{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"qPMn4bhL-RSS","executionInfo":{"status":"ok","timestamp":1650911217262,"user_tz":-120,"elapsed":18452,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}},"outputId":"c5040f03-5965-4648-e200-9b17e789f540","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Estoy en Google CoLab\n","Collecting livelossplot\n","  Downloading livelossplot-0.5.5-py3-none-any.whl (22 kB)\n","Collecting ipython==7.*\n","  Downloading ipython-7.32.0-py3-none-any.whl (793 kB)\n","\u001b[K     |████████████████████████████████| 793 kB 7.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy<1.22 in /usr/local/lib/python3.7/dist-packages (from livelossplot) (1.21.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from livelossplot) (3.2.2)\n","Requirement already satisfied: bokeh in /usr/local/lib/python3.7/dist-packages (from livelossplot) (2.3.3)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (0.2.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (0.7.5)\n","Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n","  Downloading prompt_toolkit-3.0.29-py3-none-any.whl (381 kB)\n","\u001b[K     |████████████████████████████████| 381 kB 20.3 MB/s \n","\u001b[?25hRequirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (2.6.1)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (5.1.1)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (4.8.0)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (0.18.1)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (57.4.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (0.1.3)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (4.4.2)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython==7.*->livelossplot) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython==7.*->livelossplot) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython==7.*->livelossplot) (0.2.5)\n","Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (5.1.1)\n","Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (7.1.2)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (4.2.0)\n","Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (3.13)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (2.8.2)\n","Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (21.3)\n","Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (2.11.3)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.0.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=16.8->bokeh->livelossplot) (3.0.8)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->bokeh->livelossplot) (1.15.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot) (1.4.2)\n","Installing collected packages: prompt-toolkit, ipython, livelossplot\n","  Attempting uninstall: prompt-toolkit\n","    Found existing installation: prompt-toolkit 1.0.18\n","    Uninstalling prompt-toolkit-1.0.18:\n","      Successfully uninstalled prompt-toolkit-1.0.18\n","  Attempting uninstall: ipython\n","    Found existing installation: ipython 5.5.0\n","    Uninstalling ipython-5.5.0:\n","      Successfully uninstalled ipython-5.5.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.29 which is incompatible.\n","google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.32.0 which is incompatible.\u001b[0m\n","Successfully installed ipython-7.32.0 livelossplot-0.5.5 prompt-toolkit-3.0.29\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["IPython","prompt_toolkit"]}}},"metadata":{}}],"source":["import os\n","try:\n","    from google.colab import drive\n","    COLAB = True\n","    print(\"Estoy en Google CoLab\")\n","    %tensorflow_version 2.x\n","    !pip install livelossplot\n","except:\n","    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n","    print(\"No estoy en Google CoLab\")\n","    COLAB = False"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Isa87LfU-RSZ","executionInfo":{"status":"ok","timestamp":1650911221868,"user_tz":-120,"elapsed":4612,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}},"outputId":"3b622703-ad97-439b-89d8-f7aa3be815a6","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.8.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}],"source":["import tensorflow as tf\n","tf.__version__"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"NJyxY0ce-RSa","executionInfo":{"status":"error","timestamp":1650911222950,"user_tz":-120,"elapsed":1088,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}},"outputId":"7a71373d-3fc1-4831-d0db-df9561aa4168","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-ce0b2fc30d45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mlivelossplot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPlotLossesKerasTF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdraw2compare\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import tensorflow as tf\n","try:\n","  from livelossplot import PlotLossesKerasTF\n","except:\n","  !pip install livelossplot\n","  from livelossplot import PlotLossesKerasTF\n","\n","from utils import draw2compare\n","from tensorflow.keras.layers import Layer"]},{"cell_type":"markdown","metadata":{"id":"4KnX-xes-RSc"},"source":["### VAEs cuantificadas (VQ-VAE)"]},{"cell_type":"markdown","metadata":{"id":"ZYlt210q-RSd"},"source":["Vamos a necesitar una nueva capa para llevar a cabo la cuantización. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WPtuIJXg-RSf","executionInfo":{"status":"aborted","timestamp":1650911222944,"user_tz":-120,"elapsed":12,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["class VectorQuantizer(layers.Layer):\n","    def __init__(self, num_embeddings, embedding_dim, beta=0.25, **kwargs):\n","        super().__init__(**kwargs)\n","        self.embedding_dim = embedding_dim\n","        self.num_embeddings = num_embeddings\n","        self.beta = (\n","            beta  # Mantener entre [0.25, 2] según el autor.\n","        )\n","\n","        # Inicialización del libro de códigos\n","        w_init = tf.random_uniform_initializer()\n","        self.embeddings = tf.Variable(\n","            initial_value=w_init(\n","                shape=(self.embedding_dim, self.num_embeddings), dtype=\"float32\"\n","            ),\n","            trainable=True,\n","            name=\"embeddings_vqvae\",\n","        )\n","\n","    def call(self, x):\n","        # Tamaño de la entrada\n","        input_shape = tf.shape(x)\n","        \n","        # Llevamos a cabo el aplanado para generar los vectores continuos\n","        flattened = tf.reshape(x, [-1, self.embedding_dim])\n","\n","        # Seleccionamos los índices y creamos vectores one-hot\n","        encoding_indices = self.get_code_indices(flattened)\n","        encodings = tf.one_hot(encoding_indices, self.num_embeddings)\n","        \n","        # Con los vectores one-hot y mediante un multiplicación generamos \n","        # la vectorización a partir de libro de códigos\n","        quantized = tf.matmul(encodings, self.embeddings, transpose_b=True)\n","        quantized = tf.reshape(quantized, input_shape)\n","\n","        # Calculamos los errores de alineamiento\n","        \n","        # (3r término)\n","        commitment_loss = self.beta * tf.reduce_mean(\n","            (tf.stop_gradient(quantized) - x) ** 2\n","        )\n","        \n","        # (2nd término)\n","        codebook_loss = tf.reduce_mean((quantized - tf.stop_gradient(x)) ** 2)\n","        self.add_loss(commitment_loss + codebook_loss)\n","\n","        # devolvemos la condificación haciendo un bypass \n","        quantized = x + tf.stop_gradient(quantized - x)\n","        return quantized\n","\n","    def get_code_indices(self, flattened_inputs):\n","        # Usamos la distancia euclidea para calcular los índices\n","        similarity = tf.matmul(flattened_inputs, self.embeddings)\n","        distances = (\n","            tf.reduce_sum(flattened_inputs ** 2, axis=1, keepdims=True)\n","            + tf.reduce_sum(self.embeddings ** 2, axis=0)\n","            - 2 * similarity\n","        )\n","\n","        # Derive the indices for minimum distances.\n","        encoding_indices = tf.argmin(distances, axis=1)\n","        return encoding_indices\n","    \n","\n","# El artículo usa capas residuales en códificador y el decodificador.\n","class ResidualLayer(Layer):\n","\n","    def __init__(self, kernels=128):\n","        super(ResidualLayer, self).__init__()\n","\n","        self.conv1 = layers.Conv2D(kernels, (3, 3), padding='same')\n","        self.act1 = layers.Activation('relu')\n","        self.conv2 = layers.Conv2D(kernels, (1, 1), padding='same')\n","        self.act2 = layers.Activation('relu')\n","        \n","    def call(self, inputs):\n","        x = inputs\n","        y = self.conv1(x)\n","        y = self.act1(y)\n","        y = self.conv2(y)\n","        z = keras.layers.add([x, y])\n","        z = self.act2(z)\n","\n","        return z\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3s7xZC5R-RSj","executionInfo":{"status":"aborted","timestamp":1650911222944,"user_tz":-120,"elapsed":11,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["class VQVAE(keras.models.Model):\n","    def __init__(self, train_variance, latent_dim=32, num_embeddings=128, **kwargs):\n","        super(VQVAE, self).__init__(**kwargs)\n","        self.train_variance = train_variance\n","        self.latent_dim = latent_dim\n","        self.num_embeddings = num_embeddings\n","\n","        self.vqvae = self._get_vqvae(self.latent_dim, self.num_embeddings)\n","\n","        self.total_loss_tracker = keras.metrics.Mean(name=\"loss\")\n","        self.reconstruction_loss_tracker = keras.metrics.Mean(\n","            name=\"reconstruction_loss\"\n","        )\n","        self.vq_loss_tracker = keras.metrics.Mean(name=\"vq_loss\")\n","\n","        \n","    def _get_vqvae(self, latent_dim=16, num_embeddings=64):\n","        vq_layer = VectorQuantizer(num_embeddings, latent_dim, name=\"vector_quantizer\")\n","        self.encoder = self._get_encoder(latent_dim)\n","        self.decoder = self._get_decoder(input_shape=self.encoder.output.shape[1:])\n","        inputs = keras.Input(shape=(32, 32, 3))\n","        encoder_outputs = self.encoder(inputs)\n","        quantized_latents = vq_layer(encoder_outputs)\n","        reconstructions = self.decoder(quantized_latents)\n","        return keras.Model(inputs, reconstructions, name=\"vq_vae\")\n","        \n","    def _get_encoder(self, latent_dim=16):\n","        encoder_inputs = keras.Input(shape=(32, 32, 3))\n","        x = layers.Conv2D(32, 4, activation=\"relu\", strides=2, padding=\"same\")(\n","            encoder_inputs\n","        )\n","        x = layers.Conv2D(64, 4, activation=\"relu\", strides=2, padding=\"same\")(x)\n","        x = ResidualLayer(64)(x)\n","        x = ResidualLayer(64)(x)\n","        encoder_outputs = layers.Conv2D(latent_dim, 1, padding=\"same\")(x)\n","        return keras.Model(encoder_inputs, encoder_outputs, name=\"encoder\")\n","\n","\n","    def _get_decoder(self, input_shape):\n","        latent_inputs = keras.Input(shape=input_shape)\n","        print(input_shape[-1])\n","        x = ResidualLayer(kernels=input_shape[-1])(latent_inputs)\n","        x = ResidualLayer(kernels=input_shape[-1])(x)\n","        x = layers.Conv2DTranspose(64, 4, activation=\"relu\", strides=2, padding=\"same\")(x)\n","        x = layers.Conv2DTranspose(32, 4, activation=\"relu\", strides=2, padding=\"same\")(x)\n","        decoder_outputs = layers.Conv2DTranspose(3, 4, padding=\"same\")(x)\n","        return keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n","        \n","    @property\n","    def metrics(self):\n","        return [\n","            self.total_loss_tracker,\n","            self.reconstruction_loss_tracker,\n","            self.vq_loss_tracker,\n","        ]\n","\n","    def train_step(self, x):\n","        with tf.GradientTape() as tape:\n","            # Outputs from the VQ-VAE.\n","            reconstructions = self.vqvae(x)\n","\n","            # Calculate the losses.\n","            reconstruction_loss = (\n","                tf.reduce_mean(((x - reconstructions) ** 2)) #S/ self.train_variance\n","            )\n","            total_loss = reconstruction_loss + sum(self.vqvae.losses)\n","\n","        # Backpropagation.\n","        grads = tape.gradient(total_loss, self.vqvae.trainable_variables)\n","        self.optimizer.apply_gradients(zip(grads, self.vqvae.trainable_variables))\n","\n","        # Loss tracking.\n","        self.total_loss_tracker.update_state(total_loss)\n","        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n","        self.vq_loss_tracker.update_state(sum(self.vqvae.losses))\n","\n","        # Log results.\n","        return {\n","            \"loss\": self.total_loss_tracker.result(),\n","            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n","            \"vq_loss\": self.vq_loss_tracker.result(),\n","        }\n","    \n","    \n","    def call(self, data):\n","        reconstructions = self.vqvae(data)\n","        \n","        # Calculate the losses.\n","        reconstruction_loss = (\n","            tf.reduce_mean(((data - reconstructions) ** 2)) #/ self.train_variance\n","        )\n","        total_loss = reconstruction_loss + sum(self.vqvae.losses)\n","\n","\n","        # actualizamos las métricas\n","        self.add_metric(total_loss, name='loss', aggregation='mean')\n","        self.add_metric(sum(self.vqvae.losses), name='vq_loss', aggregation='mean')\n","        self.add_metric(reconstruction_loss, name='reconstruction_loss', aggregation='mean')\n","        \n","        return reconstructions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"asRYhMPl-RSm","executionInfo":{"status":"aborted","timestamp":1650911222945,"user_tz":-120,"elapsed":12,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["vqvae_trainer = VQVAE(data_variance, latent_dim=64, num_embeddings=512)\n","vqvae_trainer.encoder.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NfkInbRU-RSn","executionInfo":{"status":"aborted","timestamp":1650911222945,"user_tz":-120,"elapsed":12,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["(x_train, _), (x_test, _) = keras.datasets.cifar10.load_data()\n","\n","x_train_scaled = (x_train / 255.0) - 0.5\n","x_test_scaled = (x_test / 255.0) - 0.5\n","\n","\n","data_variance = np.var(x_train / 255.0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X6HgdiC8-RSo","executionInfo":{"status":"aborted","timestamp":1650911222946,"user_tz":-120,"elapsed":12,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, \n","                                                          patience=5, verbose=1, min_lr=0.5e-6)   \n","\n","vqvae_trainer = VQVAE(data_variance, latent_dim=64, num_embeddings=512)\n","vqvae_trainer.compile(optimizer=keras.optimizers.Adam(2e-4))\n","vqvae_trainer.fit(x_train_scaled, epochs=100, batch_size=128, validation_data=(x_test_scaled,),\n","                 callbacks=[PlotLossesKerasTF()])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J1LluiUb-RSp","executionInfo":{"status":"aborted","timestamp":1650911222946,"user_tz":-120,"elapsed":12,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["vqvae_trainer.fit(x_train_scaled, epochs=100, batch_size=128, validation_data=(x_test_scaled,),\n","                 callbacks=[PlotLossesKerasTF()])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NhdptBoz-RSp","executionInfo":{"status":"aborted","timestamp":1650911222946,"user_tz":-120,"elapsed":13,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["vqvae_trainer.fit(x_train_scaled, epochs=100, batch_size=128, validation_data=(x_test_scaled,),\n","                 callbacks=[PlotLossesKerasTF()])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X854hxpJ-RSq","executionInfo":{"status":"aborted","timestamp":1650911222947,"user_tz":-120,"elapsed":13,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["vqvae_trainer.fit(x_train_scaled, epochs=100, batch_size=128, validation_data=(x_test_scaled,),\n","                 callbacks=[PlotLossesKerasTF()])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XJwurBhu-RSq","executionInfo":{"status":"aborted","timestamp":1650911222948,"user_tz":-120,"elapsed":14,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["vqvae_trainer.fit(x_train_scaled, epochs=100, batch_size=128, validation_data=(x_test_scaled,),\n","                 callbacks=[PlotLossesKerasTF()])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8M2uARwm-RSr","executionInfo":{"status":"aborted","timestamp":1650911222948,"user_tz":-120,"elapsed":13,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["vqvae_trainer.fit(x_train_scaled, epochs=100, batch_size=128, validation_data=(x_test_scaled,),\n","                 callbacks=[PlotLossesKerasTF()])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lPn2DdP_-RSs","executionInfo":{"status":"aborted","timestamp":1650911222948,"user_tz":-120,"elapsed":13,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["vqvae_trainer.fit(x_train_scaled, epochs=100, batch_size=128, validation_data=(x_test_scaled,),\n","                 callbacks=[PlotLossesKerasTF()])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b4JK1PkO-RSs","executionInfo":{"status":"aborted","timestamp":1650911222949,"user_tz":-120,"elapsed":14,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["image_set = x_test_scaled\n","trained_vqvae_model = vqvae_trainer.vqvae\n","idx = np.random.choice(len(image_set), 10)\n","test_images = image_set[idx] \n","reconstructions_test = trained_vqvae_model.predict(test_images)\n","\n","\n","draw2compare(test_images + 0.5, reconstructions_test + 0.5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yNxeny8E-RSt","executionInfo":{"status":"aborted","timestamp":1650911222949,"user_tz":-120,"elapsed":13,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["encoder = vqvae_trainer.vqvae.get_layer(\"encoder\")\n","quantizer = vqvae_trainer.vqvae.get_layer(\"vector_quantizer\")\n","\n","encoded_outputs = encoder.predict(test_images)\n","flat_enc_outputs = encoded_outputs.reshape(-1, encoded_outputs.shape[-1])\n","codebook_indices = quantizer.get_code_indices(flat_enc_outputs)\n","codebook_indices = codebook_indices.numpy().reshape(encoded_outputs.shape[:-1])\n","\n","\n","draw2compare(test_images + 0.5, codebook_indices) \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ELf2wN7B-RSt","executionInfo":{"status":"aborted","timestamp":1650911222950,"user_tz":-120,"elapsed":14,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"3. VAEs cuantificadas (VQ-VAE).ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}
{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"gFXv4oewDOtO","executionInfo":{"status":"ok","timestamp":1652120475077,"user_tz":-120,"elapsed":6524,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}},"outputId":"806d4194-2d9c-449f-c871-76e4f7823fd4","colab":{"base_uri":"https://localhost:8080/","height":1000}},"outputs":[{"output_type":"stream","name":"stdout","text":["Estoy en Google CoLab\n","Collecting livelossplot\n","  Downloading livelossplot-0.5.5-py3-none-any.whl (22 kB)\n","Collecting ipython==7.*\n","  Downloading ipython-7.33.0-py3-none-any.whl (793 kB)\n","\u001b[K     |████████████████████████████████| 793 kB 11.1 MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from livelossplot) (3.2.2)\n","Requirement already satisfied: numpy<1.22 in /usr/local/lib/python3.7/dist-packages (from livelossplot) (1.21.6)\n","Requirement already satisfied: bokeh in /usr/local/lib/python3.7/dist-packages (from livelossplot) (2.3.3)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (4.4.2)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (0.18.1)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (2.6.1)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (5.1.1)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (0.1.3)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (0.2.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (0.7.5)\n","Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n","  Downloading prompt_toolkit-3.0.29-py3-none-any.whl (381 kB)\n","\u001b[K     |████████████████████████████████| 381 kB 50.2 MB/s \n","\u001b[?25hRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (4.8.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (57.4.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython==7.*->livelossplot) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython==7.*->livelossplot) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython==7.*->livelossplot) (0.2.5)\n","Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (4.2.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (2.8.2)\n","Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (2.11.3)\n","Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (5.1.1)\n","Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (3.13)\n","Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.0.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=16.8->bokeh->livelossplot) (3.0.8)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->bokeh->livelossplot) (1.15.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot) (1.4.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot) (0.11.0)\n","Installing collected packages: prompt-toolkit, ipython, livelossplot\n","  Attempting uninstall: prompt-toolkit\n","    Found existing installation: prompt-toolkit 1.0.18\n","    Uninstalling prompt-toolkit-1.0.18:\n","      Successfully uninstalled prompt-toolkit-1.0.18\n","  Attempting uninstall: ipython\n","    Found existing installation: ipython 5.5.0\n","    Uninstalling ipython-5.5.0:\n","      Successfully uninstalled ipython-5.5.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.29 which is incompatible.\n","google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.33.0 which is incompatible.\u001b[0m\n","Successfully installed ipython-7.33.0 livelossplot-0.5.5 prompt-toolkit-3.0.29\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["IPython","prompt_toolkit"]}}},"metadata":{}}],"source":["import os\n","try:\n","    from google.colab import drive\n","    COLAB = True\n","    print(\"Estoy en Google CoLab\")\n","    %tensorflow_version 2.x\n","    !pip install livelossplot\n","except:\n","    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n","    import tensorflow as tf\n","    physical_devices = tf.config.list_physical_devices('GPU')\n","    tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n","    print(\"No estoy en Google CoLab\")\n","    COLAB = False"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"TeqwzDwUDOtV","executionInfo":{"status":"ok","timestamp":1652120477973,"user_tz":-120,"elapsed":2903,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["import keras\n","import os\n","import pathlib\n","import pandas as pd\n","import numpy as np \n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Bidirectional, LSTM, GRU, Dense, MaxPooling2D, Input, Embedding, Concatenate, Dropout, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Flatten\n","from tensorflow.keras.layers import Multiply, GlobalAveragePooling1D, Lambda\n","from  tensorflow.keras import backend as K\n","from tensorflow.keras import layers as tflayers\n","from tensorflow.keras import models as tfmodels\n","from livelossplot import PlotLossesKerasTF\n","from tensorflow.keras.utils import to_categorical"]},{"cell_type":"markdown","metadata":{"id":"XmpvcFT7DOtX"},"source":["# Detector de paráfrasis\n","\n","En ente ejemplo se mostrará como usar capas de embeddings y embeddings pre-entrenados para entrenar un modelo que identifique cuando dos frases son paráfrasis o no. "]},{"cell_type":"markdown","metadata":{"id":"rBoueMiQDOtZ"},"source":["Vamos a empezar descargando el conjunto de datos con la función `get_file` de keras que además de descargar el archivo lo puede descromprimir:"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"q20r9OWQDOta","executionInfo":{"status":"error","timestamp":1652120478326,"user_tz":-120,"elapsed":357,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}},"outputId":"ff75a1be-6726-4ee9-a130-100a029ab36a","colab":{"base_uri":"https://localhost:8080/","height":235}},"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-bb49c6ab031f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m data_path = keras.utils.get_file(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"parafrasis.zip\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"https://hdvirtual.us.es/discovirt/index.php/s/NZqkjMbTeEnp6w2/download\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mextract\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0marchive_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'zip'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'get_file'"]}],"source":["data_path = keras.utils.get_file(\n","    \"parafrasis.zip\",\n","    \"https://hdvirtual.us.es/discovirt/index.php/s/NZqkjMbTeEnp6w2/download\",\n","    extract=True,\n","    archive_format='zip'\n",")"]},{"cell_type":"markdown","metadata":{"id":"0Ta_LcvnDOtb"},"source":["Mostramos los archivos que contiene:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s6ki4ljpDOtb","executionInfo":{"status":"aborted","timestamp":1652120478310,"user_tz":-120,"elapsed":21,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["os.listdir(pathlib.Path(data_path).parent / 'parafrasis') "]},{"cell_type":"markdown","metadata":{"id":"cP4lU573DOtd"},"source":["Tenemos un archivo de train y uno de validación (dev) y otro de test. Vamos a hacer la lectura de los archivos (para nuetra prueba vamos a usar train y test):"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5uZp8hCvDOtd","executionInfo":{"status":"aborted","timestamp":1652120478311,"user_tz":-120,"elapsed":22,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["train = pd.read_csv(pathlib.Path(data_path).parent / 'parafrasis' / 'train.tsv', sep='\\t')\n","test = pd.read_csv(pathlib.Path(data_path).parent / 'parafrasis' / 'test_2k.tsv', sep='\\t')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p-cixrb2DOte","executionInfo":{"status":"aborted","timestamp":1652120478312,"user_tz":-120,"elapsed":23,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hfWKuxysDOtf","executionInfo":{"status":"aborted","timestamp":1652120478312,"user_tz":-120,"elapsed":22,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["train.iloc[1].sentence1, train.iloc[1].sentence2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E_dHggeHDOtg","executionInfo":{"status":"aborted","timestamp":1652120478313,"user_tz":-120,"elapsed":23,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["test.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ma1vPQcmDOth","executionInfo":{"status":"aborted","timestamp":1652120478314,"user_tz":-120,"elapsed":24,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["train.shape, test.shape"]},{"cell_type":"markdown","metadata":{"id":"f7KbsZLfDOth"},"source":["Balanceo de la respuesta:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QctyceQYDOti","executionInfo":{"status":"aborted","timestamp":1652120478314,"user_tz":-120,"elapsed":23,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["1- test.label.mean()"]},{"cell_type":"markdown","metadata":{"id":"KOH7MIrFDOti"},"source":["#### Crear un indice del vocabulario\n","\n","En primer lugar necesitamos asociar a cada palabra (mejor dicho token) un número. Para ellos usaremos la clase `Tokenizer` de Keras:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fx220zDfDOti","executionInfo":{"status":"aborted","timestamp":1652120478315,"user_tz":-120,"elapsed":24,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["corpus = list(train.sentence1.values) + list(train.sentence2.values) + \\\n","         list(test.sentence1.values) + list(test.sentence2.values)\n","corpus = [str(s) for s in corpus]      \n","tokenizer = Tokenizer(num_words=100000)\n","tokenizer.fit_on_texts(corpus)"]},{"cell_type":"markdown","metadata":{"id":"J_pr21EQDOtj"},"source":["Una vez *entrenado*, el tokenizador habrá asociado a cada palabra un número o índice:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HE_aB4yQDOtj","executionInfo":{"status":"aborted","timestamp":1652120478316,"user_tz":-120,"elapsed":25,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["tokenizer.word_index"]},{"cell_type":"markdown","metadata":{"id":"vhRR6MfzDOtk"},"source":["Al vocabulario agregamos un caracter adicional para rellenar las frases que sean más cortas de lo establecido:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B91G46gCDOtk","executionInfo":{"status":"aborted","timestamp":1652120478316,"user_tz":-120,"elapsed":25,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["total_tokens = len(tokenizer.word_index) + 1\n","total_tokens"]},{"cell_type":"markdown","metadata":{"id":"biOOH81UDOtl"},"source":["Convertimos las sentencias a sencuencias de índices y calculamos el tamaño máximo:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t30qkRvjDOtl","executionInfo":{"status":"aborted","timestamp":1652120478317,"user_tz":-120,"elapsed":26,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["train['sent1_enc'] = tokenizer.texts_to_sequences(train.sentence1.astype('str'))\n","train['sent2_enc'] = tokenizer.texts_to_sequences(train.sentence2.astype('str'))\n","test['sent1_enc'] = tokenizer.texts_to_sequences(test.sentence1.astype('str'))\n","test['sent2_enc'] = tokenizer.texts_to_sequences(test.sentence2.astype('str'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z-WrCSerDOtm","executionInfo":{"status":"aborted","timestamp":1652120478318,"user_tz":-120,"elapsed":26,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["max_size = max([train.sent1_enc.map(lambda x: len(x)).max(), train.sent2_enc.map(lambda x: len(x)).max(),\n","               test.sent1_enc.map(lambda x: len(x)).max(), test.sent2_enc.map(lambda x: len(x)).max()])\n","max_size"]},{"cell_type":"markdown","metadata":{"id":"v_T6xskIDOtm"},"source":["Ahora podemos igualar los tamaños de las sentencias agregar un token de relleno usando `pad_sequences`:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m6814IO8DOtn","executionInfo":{"status":"aborted","timestamp":1652120478318,"user_tz":-120,"elapsed":26,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["train['sent1_enc'] = list(pad_sequences(train.sent1_enc, maxlen=max_size, padding='post'))\n","train['sent2_enc'] = list(pad_sequences(train.sent2_enc, maxlen=max_size, padding='post'))\n","test['sent1_enc'] = list(pad_sequences(test.sent1_enc, maxlen=max_size, padding='post'))\n","test['sent2_enc'] = list(pad_sequences(test.sent2_enc, maxlen=max_size, padding='post'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ok5uYxclDOtn","executionInfo":{"status":"aborted","timestamp":1652120478319,"user_tz":-120,"elapsed":27,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["train.head()"]},{"cell_type":"markdown","metadata":{"id":"IqHbUg6uDOto"},"source":["Creamos los conjuntos de entrenamiento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bChtvY_mDOto","executionInfo":{"status":"aborted","timestamp":1652120478319,"user_tz":-120,"elapsed":27,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["X1, X2 = np.array(train.sent1_enc.to_list()), np.array(train.sent2_enc.to_list())\n","X_val1, X_val2 = np.array(test.sent1_enc.to_list()), np.array(test.sent2_enc.to_list())"]},{"cell_type":"markdown","metadata":{"id":"3hNOpkerDOtp"},"source":["## Usando embeddings pre-entrenados\n","\n","### Lectura de los embeddings\n","\n","En primer lugar debemos descargar los embeddings pre-entrenados. En este caso vamos a usar GloVe. El arhivo comprimido son (906MB)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pBAm81qDDOtp","executionInfo":{"status":"aborted","timestamp":1652120478320,"user_tz":-120,"elapsed":28,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["data_path = keras.utils.get_file(\n","    \"glove.zip\",\n","    \"https://hdvirtual.us.es/discovirt/index.php/s/dBfebSHNqKfeZTR/download\",\n","    extract=True,\n","    archive_format='zip'\n",")"]},{"cell_type":"markdown","metadata":{"id":"4jjojdbNDOtp"},"source":["Una vez descargado hacemos la lectura de los embeddings creando un diccionario cuya clave es la palabra y el valor es el vector:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8hQnhqgDDOtp","executionInfo":{"status":"aborted","timestamp":1652120478320,"user_tz":-120,"elapsed":28,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["glove_path = pathlib.Path(data_path).parent / 'SBW-vectors-300-min5.txt'\n","\n","embeddings_index = {}\n","with open(glove_path) as f:\n","    for line in f:\n","        word, coefs = line.split(maxsplit=1)\n","        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n","        embeddings_index[word] = coefs\n","\n","print(\"Encontrados %s vectors.\" % len(embeddings_index))"]},{"cell_type":"markdown","metadata":{"id":"wLBqaHDCDOtq"},"source":["Ahora tenemos que preparar una matriz que usará la capa de embedding de Keras. Esta matriz es solo una matriz de numpy donde la entra i-ésima corresponde al vector de la palabra i-ésima de nuestro vocabulario:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CmszXRXaDOtq","executionInfo":{"status":"aborted","timestamp":1652120478321,"user_tz":-120,"elapsed":28,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["embedding_matrix = np.zeros((total_tokens, 300))\n","count = 0\n","palabras_no_encontradas = []\n","for word, i in tokenizer.word_index.items():\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","        embedding_matrix[i] = embedding_vector\n","    else:\n","        palabras_no_encontradas.append(word)\n","        count += 1\n","print(\"No se encontraron vectores para %d palabras (de %d)\" % (count, total_tokens))        "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ASdHDQakDOtq","executionInfo":{"status":"aborted","timestamp":1652120478321,"user_tz":-120,"elapsed":28,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["palabras_no_encontradas"]},{"cell_type":"markdown","metadata":{"id":"JDmf4smIDOtr"},"source":["Dado que ahora cada una de nuestras palabras es un vector, podemos hacer operaciones vectoriales. Por ejemplo ¿que pasaría si a la palabra *rey* le quitamos la carga semántica de *hombre* y le sumamos la carga semántica de *mujer*?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wcAEsvFPDOtr","executionInfo":{"status":"aborted","timestamp":1652120478322,"user_tz":-120,"elapsed":29,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["from scipy import spatial\n","v = embeddings_index.get('rey') - embeddings_index.get('hombre') + embeddings_index.get('mujer') \n","sorted([(w, spatial.distance.cosine(v, embeddings_index.get(w)))\n","        for w in tokenizer.word_index.keys() \n","        if embeddings_index.get(w) is not None ],\n","       key=lambda x: x[1])\n"]},{"cell_type":"markdown","metadata":{"id":"LJaLj4pODOtr"},"source":["## Modelo recurrente bidireccional con distancia coseno\n","\n","Vamos a necesitar un par de funciones que calculen la distancia coseno entre dos vectores:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YLnvJ79TDOtr","executionInfo":{"status":"aborted","timestamp":1652120478322,"user_tz":-120,"elapsed":28,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["def cosine_distance(vests):\n","    x, y = vests\n","    x = K.l2_normalize(x, axis=-1)\n","    y = K.l2_normalize(y, axis=-1)\n","    return -K.mean(x * y, axis=-1, keepdims=True)\n","\n","def cos_dist_output_shape(shapes):\n","    shape1, shape2 = shapes\n","    return (shape1[0],1)"]},{"cell_type":"markdown","metadata":{"id":"NjShYoJ_DOts"},"source":["Ahora nos podemos crear una red que recibirá dos entradas. Cada entrada será codificada con los embedings preentrenados y pasarán por las LSTMs bidireccionales. La salidas de las LSTMs (los estados) los usaremos para calcular la distancia coseno usando la capa *Lambda*. Por último con una capa densa obtenemos la salida:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ve97BffLDOts","executionInfo":{"status":"aborted","timestamp":1652120478323,"user_tz":-120,"elapsed":29,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["s1 = Input(shape=(max_size, ), dtype=\"int64\")\n","s2 = Input(shape=(max_size, ), dtype=\"int64\")\n","\n","embedding = Embedding(total_tokens, 300, weights=[embedding_matrix], trainable=False, input_length=max_size)\n","\n","e1 = embedding(s1)\n","e2 = embedding(s2)\n","\n","recurrent = Bidirectional(LSTM(64, return_sequences=True))\n","x = recurrent(e1)\n","y = recurrent(e2)\n","z = Lambda(cosine_distance, output_shape=cos_dist_output_shape)([x, y])\n","z = Flatten()(z)\n","preds = Dense(2, activation=\"softmax\")(z)\n","\n","model = Model([s1, s2], preds)\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"asp0QGpdDOtt","executionInfo":{"status":"aborted","timestamp":1652120478323,"user_tz":-120,"elapsed":29,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n","model.fit([X1, X2], to_categorical(train.label.values),\n","          epochs=10,\n","          batch_size=32,\n","          validation_data=([X_val1, X_val2], to_categorical(test.label.values)),\n","          callbacks=[PlotLossesKerasTF()])"]},{"cell_type":"markdown","metadata":{"id":"d8QAgFYbDOtt"},"source":["## LSTM Bidireccional con red de relevancia\n","\n","Basado en el artículo [Bidirectional Long Short-Term Memory with Gated Relevance Network for Paraphrase Identification](https://link.springer.com/chapter/10.1007/978-3-319-50496-4_49)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6zB6y0WSDOtt","executionInfo":{"status":"aborted","timestamp":1652120478324,"user_tz":-120,"elapsed":29,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["from keras.layers import Layer\n","from tensorflow.keras import backend as K\n","class GatedRelevanceNetwork(Layer):\n","    def __init__(self, output_dim,\n","            weights_initializer=\"glorot_uniform\",\n","            bias_initializer=\"zeros\", **kwargs):\n","        self.output_dim = output_dim\n","        self.weights_initializer = weights_initializer\n","        self.bias_initializer = bias_initializer\n","        super(GatedRelevanceNetwork, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        batch_size, len1, emb_dim = input_shape[0]\n","        _, len2, _ = input_shape[1]\n","        \n","        # Weights initialization\n","        # Bilinear Tensor Product weights\n","        self.Wb = self.add_weight(name='weights_btp',\n","                                  shape=(self.output_dim, emb_dim, emb_dim),\n","                                  initializer=self.weights_initializer,\n","                                  trainable=True)\n","\n","        # Pesos de la red totalmente conectada\n","        self.Wd = self.add_weight(name='weights_sln',\n","                                  shape=(2*emb_dim, self.output_dim),\n","                                  initializer=self.weights_initializer,\n","                                  trainable=True)\n","\n","        # Pesos de la puerta (ver el artículo)\n","        self.Wg = self.add_weight(name='weights_gate',\n","                                  shape=(2*emb_dim, self.output_dim),\n","                                  initializer=self.weights_initializer,\n","                                  trainable=True)\n","\n","        # Sesgo\n","        self.bg = self.add_weight(name='bias_gate',\n","                                  shape=(self.output_dim,),\n","                                  initializer=self.bias_initializer,\n","                                  trainable=True)\n","\n","        # Sesgo general\n","        self.b = self.add_weight(name='bias',\n","                                 shape=(self.output_dim,),\n","                                 initializer=self.bias_initializer,\n","                                 trainable=True)\n","\n","        # Pesos del canal (ver el artículo)\n","        self.u = self.add_weight(name=\"channel_weights\",\n","                                 shape=(self.output_dim, 1),\n","                                 initializer=self.weights_initializer,\n","                                 trainable=True)\n","\n","        super(GatedRelevanceNetwork, self).build(input_shape)\n","\n","    def call(self, x):\n","        e1 = x[0]\n","        e2 = x[1]\n","\n","        batch_size = K.shape(e1)[0]\n","        _, len1, emb_dim = K.int_shape(e1)\n","        _, len2, _ = K.int_shape(e2)\n","\n","        # Se repiten las matrices para generar todas las combinaciones\n","        ne1 = K.reshape(K.repeat_elements(K.expand_dims(e1, axis=2), len2, axis=2),\n","                       (batch_size, len1*len2, emb_dim))\n","        ne2 = K.reshape(K.repeat_elements(K.expand_dims(e2, axis=1), len1, axis=1),\n","                       (batch_size, len1*len2, emb_dim))\n","\n","        # Se repite la segunda matriz para poder hacer el producto bilineal\n","        ne2_k = K.repeat_elements(K.expand_dims(ne2, axis=-1), self.output_dim, axis=-1)\n","\n","        # Producto\n","        btp = K.sum(ne2_k * K.permute_dimensions(K.dot(ne1, self.Wb), (0,1,3,2)), axis=2)\n","        btp = K.reshape(btp, (batch_size, len1, len2, self.output_dim))\n","\n","        # Concatemos para pasar por la red totalmente conectada\n","        e = K.concatenate([ne1, ne2], axis=-1)\n","\n","        # Red totalmente conectada\n","        sln = K.tanh(K.dot(e, self.Wd))\n","        sln = K.reshape(sln, (batch_size, len1, len2, self.output_dim))\n","\n","        # Puerta \n","        g = K.sigmoid(K.dot(e, self.Wg) + self.bg)\n","        g = K.reshape(g, (batch_size, len1, len2, self.output_dim))\n","\n","        # Relevancia\n","        s = K.dot(g*btp + (1-g)*sln + self.b, self.u)\n","\n","        return s\n","\n","    def compute_output_shape(self, input_shape):\n","        shape1 = input_shape[0]\n","        shape2 = input_shape[1]\n","        return (shape1[0], shape1[1], shape2[1], 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4UoxVkijDOtu","executionInfo":{"status":"aborted","timestamp":1652120478324,"user_tz":-120,"elapsed":29,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["def create_model(input_shape, embeddings_dim, embeddings_matrix, vocab_size,\n","                      max_seq_length, trainable_embeddings, dropout,\n","                      lstm_hidden_units, attention_channels, pool_size,\n","                      fc_hidden_units):\n","   \n","    X1_input = Input(input_shape, name=\"input_X1\")\n","    X2_input = Input(input_shape, name=\"input_X2\")\n","\n","    # Embeddings\n","    embeddings = Embedding(vocab_size,\n","                    embeddings_dim,\n","                    weights=[embeddings_matrix],\n","                    input_length=input_shape[0],\n","                    trainable=trainable_embeddings,\n","                    mask_zero=False)\n","    X1 = embeddings(X1_input)\n","    X2 = embeddings(X2_input)\n","    \n","    # Recurrencia\n","    encoder = Bidirectional(LSTM(lstm_hidden_units, return_sequences=True))\n","\n","    X1_encoded = encoder(X1)\n","    X2_encoded = encoder(X2)\n","\n","    # Mecanismo de atención \n","    X = GatedRelevanceNetwork(attention_channels, name=\"grn\")([X1_encoded, X2_encoded])\n","    #X = BatchNormalization()(X)\n","\n","    # Reducción de dimensionalidad\n","    X = MaxPooling2D(pool_size=(pool_size, pool_size), strides=(pool_size, pool_size), \n","                     padding='valid',\n","                        data_format=\"channels_last\",\n","                        name=\"max_pool\")(X)\n","    X = Flatten()(X)\n","\n","    # Clasificación\n","    X = Dense(fc_hidden_units, activation=\"tanh\", name=\"mlp\")(X)\n","    X = Dropout(dropout)(X)\n","    X = Dense(2, activation=\"softmax\", name=\"output\")(X)\n","\n","    model = Model(inputs=[X1_input, X2_input], outputs=X, name=\"GRN_model\")\n","\n","    return model\n","\n","\n","dropout = 0.5\n","trainable_embeddings = False\n","lstm_hidden_units = 50\n","attention_channels = 2\n","pool_size = 3\n","fc_hidden_units = 128\n","use_class_weight = False\n","input_shape = (max_size,)\n","embedding_dim = 300\n","vocab_size = total_tokens\n","\n","model = create_model(input_shape,\n","                      embedding_dim, embedding_matrix, vocab_size,\n","                      max_size, trainable_embeddings, dropout,\n","                      lstm_hidden_units, attention_channels, pool_size,\n","                      fc_hidden_units)\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N7EANffQDOtv","executionInfo":{"status":"aborted","timestamp":1652120478325,"user_tz":-120,"elapsed":30,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":["from keras import optimizers\n","optimizer = optimizers.Adam()\n","model.compile(optimizer=optimizer,\n","            loss=\"categorical_crossentropy\",\n","            metrics=[\"accuracy\"])\n","model.fit([X1, X2], to_categorical(train.label.values),\n","          epochs=10,\n","          batch_size=32,\n","          validation_data=([X_val1, X_val2], to_categorical(test.label.values)),\n","          callbacks=[PlotLossesKerasTF()])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qmn113bBDOtv","executionInfo":{"status":"aborted","timestamp":1652120478325,"user_tz":-120,"elapsed":29,"user":{"displayName":"Germán Lorenz","userId":"17546947320916964948"}}},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"1. Detector de paráfrasis con embeddings pre-entrenados.ipynb","provenance":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}